{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading results from  directory ../results_blackbox/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14016/14016 [00:07<00:00, 1931.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803 results files loaded, 0 (0.0%) of which are updated\n",
      "0 fails:\n",
      "bad bsr: []\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Collates json-formatted results, cleans them up and saves them as .feather\n",
    "files.\"\"\"\n",
    "# Author: William La Cava, williamlacava@gmail.com\n",
    "# SRBENCH\n",
    "# License: GPLv3\n",
    "\n",
    "################################################################################\n",
    "# Ground-truth problems\n",
    "################################################################################\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "rdir = '../results_sym_data/'\n",
    "print('reading results from  directory', rdir)\n",
    "\n",
    "\n",
    "symbolic_algs = [\n",
    "    'AFP', \n",
    "    'AFP_FE',\n",
    "    'BSR',\n",
    "    'DSR',\n",
    "    'FFX',\n",
    "    'FEAT',\n",
    "    'EPLEX',\n",
    "    'GP-GOMEA',\n",
    "    'gplearn',\n",
    "    'ITEA', \n",
    "    'MRGP', \n",
    "    'Operon',\n",
    "    'SBP-GP',\n",
    "    'AIFeynman',\n",
    "\n",
    "    'Brush',\n",
    "    'Brush wo split',\n",
    "    'Brush (D-UCB1)',\n",
    "    'Brush (C-D-UCB1)',\n",
    "    'Brush (D-TS)',\n",
    "    'Brush (C-D-TS)',\n",
    "    'Brush wo split (D-UCB1)',\n",
    "]\n",
    "nongp_algs = [\n",
    "    'BSR',\n",
    "    'DSR',\n",
    "    'AIFeynman'\n",
    "]\n",
    "gp_algs = [\n",
    "    'AFP', \n",
    "    'AFP_FE',\n",
    "    'FFX',\n",
    "    'FEAT',\n",
    "    'EPLEX',\n",
    "    'GP-GOMEA',\n",
    "    'gplearn',\n",
    "    'ITEA', \n",
    "    'MRGP', \n",
    "    'Operon',\n",
    "    'SBP-GP',\n",
    "\n",
    "    'Brush',\n",
    "    'Brush wo split',\n",
    "    'Brush (D-UCB1)',\n",
    "    'Brush (C-D-UCB1)',\n",
    "    'Brush (D-TS)',\n",
    "    'Brush (C-D-TS)',\n",
    "    'Brush wo split (D-UCB1)',\n",
    "]\n",
    "\n",
    "##########\n",
    "# load data from json\n",
    "##########\n",
    "\n",
    "frames = []\n",
    "excluded_datasets = [\n",
    "    'feynman_test_10',\n",
    "    'feynman_I_26_2',\n",
    "    'feynman_I_30_5'\n",
    "]\n",
    "excluded_cols = [\n",
    "    'params'\n",
    "]\n",
    "fails = []\n",
    "bad_bsr = []\n",
    "updated = 0\n",
    "for f in tqdm(glob(rdir + '/*/*.json')):\n",
    "\n",
    "    if os.path.exists(f+'.updated'):\n",
    "        f += '.updated'\n",
    "        updated += 1\n",
    "    if 'cv_results' in f: \n",
    "        continue\n",
    "    if 'EHC' in f:\n",
    "        continue\n",
    "\n",
    "    if any([ed in f for ed in excluded_datasets]):\n",
    "        continue\n",
    "\n",
    "    # Filtering brushes\n",
    "    # if not any([c in f for c in ['brush_500','brush_D_UCB1_500','brush_wo_split_500','brush_wo_split_D_UCB1_500',]]):\n",
    "    #     continue\n",
    "\n",
    "    if \"_dso_\" not in f:\n",
    "        continue\n",
    "\n",
    "    try: \n",
    "        r = json.load(open(f,'r'))\n",
    "        if isinstance(r['symbolic_model'],list):\n",
    "            print('WARNING: list returned for model:',f)\n",
    "            bad_bsr.append(f)\n",
    "            sm = ['B'+str(i)+'*'+ri for i, ri in enumerate(r['symbolic_model'])]\n",
    "            sm = '+'.join(sm)\n",
    "            r['symbolic_model'] = sm\n",
    "            \n",
    "        sub_r = {k:v for k,v in r.items() if k not in excluded_cols}\n",
    "    #     df = pd.DataFrame(sub_r)\n",
    "        frames.append(sub_r) \n",
    "    #     print(f)\n",
    "    #     print(r.keys())\n",
    "    except Exception as e:\n",
    "        fails.append([f,e])\n",
    "        pass\n",
    "    \n",
    "print('{} results files loaded, {} ({:.1f}%) of which are '\n",
    "\t'updated'.format(len(frames), updated, updated/len(frames)*100))\n",
    "print(len(fails),'fails:')\n",
    "for f in fails: \n",
    "    print(f[0])\n",
    "print('bad bsr:',bad_bsr)\n",
    "df_results = pd.DataFrame.from_records(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'symbolic_error_is_zero'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/srbench/lib/python3.9/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.conda/envs/srbench/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/srbench/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'symbolic_error_is_zero'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m df_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_zero_test\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mmax\u001b[39m(x,\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbolic_error_is_zero\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbolic_error_is_constant\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbolic_fraction_is_constant\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 11\u001b[0m     df_results\u001b[38;5;241m.\u001b[39mloc[:,col] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(df_results\u001b[38;5;241m.\u001b[39malgorithm\u001b[38;5;241m.\u001b[39munique()))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# remove 'Regressor' from names\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/srbench/lib/python3.9/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.conda/envs/srbench/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'symbolic_error_is_zero'"
     ]
    }
   ],
   "source": [
    "##########\n",
    "# cleanup\n",
    "##########\n",
    "\n",
    "df_results = df_results.rename(columns={'time_time':'training time (s)'})\n",
    "df_results.loc[:,'training time (hr)'] = df_results['training time (s)']/3600\n",
    "\n",
    "# add modified R2 with 0 floor\n",
    "df_results['r2_zero_test'] = df_results['r2_test'].apply(lambda x: max(x,0))\n",
    "for col in ['symbolic_error_is_zero', 'symbolic_error_is_constant', 'symbolic_fraction_is_constant']:\n",
    "    df_results.loc[:,col] = df_results[col].fillna(False)\n",
    "\n",
    "print(','.join(df_results.algorithm.unique()))\n",
    "\n",
    "# remove 'Regressor' from names\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('Regressor','')) \n",
    "\n",
    "#Rename SGD to Linear\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: 'Linear' if x=='SGD' else x)\n",
    "\n",
    "# rename sembackpropgp to SBP\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('sembackpropgp','SBP-GP'))\n",
    "\n",
    "# rename FE_AFP to AFP_FE\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('FE_AFP','AFP_FE'))\n",
    "\n",
    "# rename GPGOMEA to GP-GOMEA\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('GPGOMEA','GP-GOMEA'))\n",
    "\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush_500', 'Brush'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush_D_UCB1_500', 'Brush (D-UCB1)'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush_wo_split_500','Brush wo split'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush_wo_split_D_UCB1_500','Brush wo split (D-UCB1)'))\n",
    " \n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush_wo_split_D_UCB1','Brush wo split (D-UCB1)'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush_wo_split','Brush wo split'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush_D_UCB1', 'Brush (D-UCB1)'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush_C_D_UCB1', 'Brush (C-D-UCB1)'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush_D_TS', 'Brush (D-TS)'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush_C_D_TS', 'Brush (C-D-TS)'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('brush', 'Brush'))\n",
    "\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('e2et','E2E'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('tpsr','TPSR+E2E'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('dso','uDSR'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('nesymres10M','NeSymRes 10M'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('nesymres100M','NeSymRes 100M'))\n",
    "\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('PSTreeRegressor','PS-Tree'))\n",
    "df_results['algorithm'] = df_results['algorithm'].apply(lambda x: x.replace('pstree','PS-Tree'))\n",
    "\n",
    "df_results['symbolic_alg'] = df_results['algorithm'].apply(lambda x: x in symbolic_algs)\n",
    "\n",
    "# indicator of strogatz or feynman\n",
    "df_results['data_group'] = df_results['dataset'].apply(lambda x: 'Feynman' if 'feynman' in x else 'Strogatz') \n",
    "\n",
    "# filling empty target noise with zeros\n",
    "# df_results['target_noise']  = df_results['target_noise'].fillna(0)\n",
    "# df_results['feature_noise'] = df_results['feature_noise'].fillna(0)\n",
    "\n",
    "##########\n",
    "# compute symbolic solutions\n",
    "##########\n",
    "print(df_results.columns)\n",
    "display(df_results.sample(3).T)\n",
    "df_results.loc[:,'symbolic_solution'] = df_results[['symbolic_error_is_zero',\n",
    "                                                    'symbolic_error_is_constant',\n",
    "                                                    'symbolic_fraction_is_constant']\n",
    "                                                   ].apply(any,raw=True, axis=1)\n",
    "df_results.loc[:,'symbolic_solution'] = df_results['symbolic_solution'] & ~df_results['simplified_symbolic_model'].isna() \n",
    "df_results.loc[:,'symbolic_solution'] = df_results['symbolic_solution'] & ~(df_results['simplified_symbolic_model'] == '0')\n",
    "df_results.loc[:,'symbolic_solution'] = df_results['symbolic_solution'] & ~(df_results['simplified_symbolic_model'] == 'nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['algorithm','dataset']:\n",
    "    print(df_results[col].nunique(), col+'s')\n",
    "\n",
    "print('mean trial count:')\n",
    "print(df_results.groupby('algorithm')['dataset'].count().sort_values()\n",
    "      / df_results.dataset.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_results.shape)\n",
    "##########\n",
    "# save results\n",
    "##########\n",
    "df_results.to_feather('../results/ground-truth_results_dso2.feather')\n",
    "print('results saved to ../results/ground-truth_results_dso2.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srbench-brush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
