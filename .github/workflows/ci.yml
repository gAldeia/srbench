# This is a basic workflow to help you get started with Actions

name: CI

# Controls when the action will run. 
on:
  # Triggers the workflow on push or pull request events but only for the master and dev branches
  push:
    branches:
      - master
      - dev
      - docker-fix  # temporary for testing
  pull_request:
    branches: 
      - master 
      - dev 

env: 
  CACHE_NUMBER: 1

jobs:
  check:
    name: Check env changes
    outputs:
      run_job: ${{ steps.check_files.outputs.run_job }}
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    env:
      skip: 'true'
    steps:
      - 
        name: Checkout code
        uses: actions/checkout@v2
        with:
          fetch-depth: 2
        if: env.skip == 'false'
      - 
        name: check modified files
        id: check_files
        run: |
          if ${{ env.skip }} ; then
              echo "::set-output name=run_job::true"
          else
            echo "=============== list modified files ==============="
            git diff --name-only HEAD^ HEAD
            echo "========== check paths of modified files =========="
            git diff --name-only HEAD^ HEAD > files.txt
            while IFS= read -r file
            do
              echo $file
              if [[ $file == environment.yml ]]; then
                echo "::set-output name=run_job::true"
              elif [[ $file != experiment/methods/src/* ]]; then
                echo "This modified file is not under the 'src' folder."
                echo "::set-output name=run_job::false"
                break
              else
                echo "::set-output name=run_job::true"
              fi
            done < files.txt
          fi

  ################################################################################
  # environment setup
  ################################################################################
  build:
    runs-on: ubuntu-latest
    needs: check
    if: needs.check.outputs.run_job == 'true'
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - 
        name: Checkout code
        uses: actions/checkout@v2
      - 
        name: Setup Mambaforge
        uses: conda-incubator/setup-miniconda@v2
        with:
          miniforge-variant: Mambaforge
          miniforge-version: latest
          activate-environment: srbench
          use-mamba: true
      - 
        name: Set cache date
        run: echo "DATE=$(date +'%Y%m%d')" >> $GITHUB_ENV
      - 
        name: Cache conda
        uses: actions/cache@v2
        with:
          path: /usr/share/miniconda3/envs/srbench
          key: ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{ hashFiles('environment.yml') }}-${{ env.DATE }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{ hashFiles('environment.yml') }}-${{ env.DATE }}
            ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{ hashFiles('environment.yml') }}
        id: cache
      - 
        name: Update environment
        if: steps.cache.outputs.cache-hit != 'true'
        run: mamba env update -n srbench -f environment.yml --prune
      # -
      #   name: Activate Environment
      #   run: |
      #     conda activate srbench
      #     conda info
      - 
        name: Install SR methods
        run: |
          mamba run -n srbench bash install.sh
      - 
        name: Test Evaluate Model 
        run: |
          cd experiment
          ./test_evaluate_model.sh
      - 
        name: Test Tuned Models
        run: python -m pytest -v test_tuned_models.py
  test_setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      matrix-tuned: ${{ steps.set-matrix-tuned.outputs.matrix }}
    steps:
      - id: generate alg list
        run: bash get_algorithm_list.sh
      - id: set-matrix
        run: |
          echo "::set-output name=matrix::${cat ci/algs.json}"
      - id: set-matrix-tuned
        run: |
          echo "::set-output name=matrix::${cat ci/algs-tuned.json}"
  test_evaluate:
    runs-on: ubuntu-latest
    needs: 
      - build
      - test_setup
    strategy:
      matrix: ${{fromJSON(needs.test_setup.outputs.matrix)}}
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - 
        name: Checkout code
        uses: actions/checkout@v2
      - 
        name: Setup Mambaforge
        uses: conda-incubator/setup-miniconda@v2
        with:
          miniforge-variant: Mambaforge
          miniforge-version: latest
          activate-environment: srbench
          use-mamba: true
      - 
        name: Set cache date
        run: echo "DATE=$(date +'%Y%m%d')" >> $GITHUB_ENV
      - 
        name: Cache conda
        uses: actions/cache@v2
        with:
          path: /usr/share/miniconda3/envs/srbench
          key: ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{ hashFiles('environment.yml') }}-${{ env.DATE }}-${{ github.sha }}
        id: cache
      - name: Evaluate Model
        if: steps.cache.outputs.cache-hit == 'true'
        run: |
          cd experiment
          mamba run -n srbench python -m pytest -v test_evaluate_model.py --ml ${{ matrix.ml }}

  test_tuned:
    runs-on: ubuntu-latest
    needs: 
      - build
      - test_setup
    defaults:
      run:
        shell: bash -l {0}
    strategy:
      matrix: ${{fromJSON(needs.test_setup.outputs.matrix-tuned)}}
    steps:
      - 
        name: Checkout code
        uses: actions/checkout@v2
      - 
        name: Setup Mambaforge
        uses: conda-incubator/setup-miniconda@v2
        with:
          miniforge-variant: Mambaforge
          miniforge-version: latest
          # activate-environment: srbench
          use-mamba: true
      - 
        name: Set cache date
        run: echo "DATE=$(date +'%Y%m%d')" >> $GITHUB_ENV
      - 
        name: Cache conda
        uses: actions/cache@v2
        with:
          path: /usr/share/miniconda3/envs/srbench
          key: ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{ hashFiles('environment.yml') }}-${{ env.DATE }}-${{ github.sha }}
        id: cache
      - name: Evaluate Tuned Model
        if: steps.cache.outputs.cache-hit == 'true'
        run: |
          cd experiment
          mamba run -n srbench python -m pytest -v test_tuned_models.py --ml ${{ matrix.ml }}
